# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: MIT
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the "Software"),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.

apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Release.Name }}-client"
spec:
  template:
    spec:
      serviceAccountName: {{ include "benchmark_chart.serviceAccountName" . }}
      restartPolicy: Never
{{- if .Values.ngcImagePullSecretName }}
      imagePullSecrets:
      - name: {{ .Values.ngcImagePullSecretName }}
{{- end }}
      {{- if .Values.tolerations }}
      tolerations:
{{ toYaml .Values.tolerations | indent 8 }}
      {{- end }}
      {{- if .Values.environment.RESULTS_PATH }}
      volumes:
      - name: results-volume
        hostPath:
          path: {{ .Values.environment.RESULTS_PATH }}
          type: DirectoryOrCreate
      {{- end }}
      containers:
      - name: benchmarking-client
        image: {{ .Values.environment.BENCHMARK_SERVER_IMAGE }}
        {{- if .Values.environment.RESULTS_PATH }}
        volumeMounts:
        - name: results-volume
          mountPath: {{ .Values.environment.RESULTS_PATH }}
        {{- end }}
        command: ["sh", "-c"]
        args:
          - |
            BASE_URL="http://{{ .Release.Name }}-server:{{ .Values.environment.SERVER_PORT }}"
            HEALTH_CHECK_URL="${BASE_URL}/${SERVER_HEALTH_CHECK_ENDPOINT}"
            echo '{ "model": "'$MODEL_NAME'", "num_gpus": '$NUM_GPUS', "concurrency_range": "'$CONCURRENCY_RANGE'", "use_cases": "'$USE_CASES'" }' > metadata.json

            export PERCENT_COMPLETE=1

            echo "Setup directory for results"
            if [ -z "${RESULTS_PATH}" ]; then
              RESULTS_DIR=${NVCT_RESULTS_DIR}
            else
              RESULTS_DIR=${RESULTS_PATH}
            fi
            mkdir -p ${RESULTS_DIR}

            export EXPORT_FOLDER="nothing_new"
            mkdir -p ${RESULTS_DIR}/${EXPORT_FOLDER}

            function update_progress() {
              date=$(python3 -c 'import datetime; print(datetime.datetime.now(datetime.timezone.utc).strftime("%Y-%m-%dT%H:%M:%S.%fZ"))')
              msg='{"taskId": "'${NVCT_TASK_ID}'",  "percentComplete": '${PERCENT_COMPLETE}',  "name": "'${EXPORT_FOLDER}'",  "metadata": '$(cat metadata.json)',  "lastUpdatedAt": "'${date}'"}'
              echo "Updating progress with message: ${msg}"
              echo ${msg} > "${NVCT_PROGRESS_FILE_PATH}"
            }
            update_progress
            
            # Wait for the server to be ready
            echo "Waiting for server to be ready..."
            sleep 5
            until curl -s -o /dev/null -w "%{http_code}" "$HEALTH_CHECK_URL" | grep -q "^200$"; do
              echo "Server not ready yet ($HEALTH_CHECK_URL), waiting..."
              update_progress
              sleep 5
            done
            sleep ${SERVER_STARTUP_DELAY:-10}
            echo "Server is ready!"
            TIMESTAMP=$(date +%s)

            echo "Starting the benchmark!"

            # Loop through concurrency values defined in values.yaml
            for CONCURRENCY in ${CONCURRENCY_RANGE}; do
              # Loop through use cases defined in values.yaml
              for value in $USE_CASES; do

                # Calculate total requests using values from values.yaml
                TOTAL_REQUESTS=$((REQUEST_MULTIPLIER * CONCURRENCY))
                if [ "$TOTAL_REQUESTS" -lt $MIN_REQUESTS ]; then
                  TOTAL_REQUESTS=$MIN_REQUESTS
                fi

                echo "Concurrency: $CONCURRENCY"

                # Extract the use case name and values
                use_case=$(echo "$value" | cut -d':' -f1)

                if [ "$use_case" != "chat" ] && [ "$use_case" != "embeddings" ]; then
                  echo "Error: Unsupported use case '$use_case'. Only 'chat' and 'embeddings' are supported."
                  exit 1
                fi

                if [ "$use_case" == "chat" ]; then
                  use_case="chat"

                  INPUT_SEQUENCE_LENGTH=$(echo "$value" | cut -d':' -f2 | cut -d'/' -f1)
                  OUTPUT_SEQUENCE_LENGTH=$(echo "$value" | cut -d':' -f2 | cut -d'/' -f2)

                  SERVER_ENDPOINT="${BASE_URL}"

                  echo "Use Case: $use_case"
                  echo "Input Sequence Length: $INPUT_SEQUENCE_LENGTH"
                  echo "Output Sequence Length: $OUTPUT_SEQUENCE_LENGTH"
                  echo "----------------"

                  # Create export file name using values from values.yaml
                  export EXPORT_FOLDER="${MODEL_NAME_CLEANED}_${NUM_GPUS}_${CONCURRENCY}_${use_case}_${INPUT_SEQUENCE_LENGTH}_${OUTPUT_SEQUENCE_LENGTH}_${TIMESTAMP}"

                  # Execute command with proper variable expansion
                  OUTPUT_DIR=${RESULTS_DIR}/${EXPORT_FOLDER}
                  genai-perf profile \
                  -m ${MODEL_NAME} \
                  --endpoint-type ${use_case} \
                  --streaming -u ${SERVER_ENDPOINT} \
                  --num-prompts ${TOTAL_REQUESTS} \
                  --synthetic-input-tokens-mean ${INPUT_SEQUENCE_LENGTH} \
                  --synthetic-input-tokens-stddev 0 \
                  --concurrency ${CONCURRENCY} \
                  --output-tokens-mean ${OUTPUT_SEQUENCE_LENGTH} \
                  --extra-inputs max_tokens:${OUTPUT_SEQUENCE_LENGTH} \
                  --extra-inputs min_tokens:${OUTPUT_SEQUENCE_LENGTH} \
                  --extra-inputs ignore_eos:true \
                  --artifact-dir ${OUTPUT_DIR} \
                  --tokenizer ${MODEL_TOKENIZER} \
                  -- -v --max-threads=${CONCURRENCY} --request-count ${TOTAL_REQUESTS}
                fi
                if [ "$use_case" == "embeddings" ]; then
                  use_case="embeddings"

                  BATCH_SIZE=$(echo "$value" | cut -d':' -f2)

                  SERVER_ENDPOINT="${BASE_URL}"

                  echo "Use Case: $use_case"
                  echo "Batch Size: $BATCH_SIZE" 
                  echo "----------------"

                  # Create export file name using values from values.yaml
                  export EXPORT_FOLDER="${MODEL_NAME_CLEANED}_${NUM_GPUS}_${CONCURRENCY}_${use_case}_${BATCH_SIZE}_${TIMESTAMP}"

                  # Execute command with proper variable expansion
                  OUTPUT_DIR=${RESULTS_DIR}/${EXPORT_FOLDER}
                  genai-perf profile \
                  -m ${MODEL_NAME} \
                  --endpoint-type ${use_case} \
                  -u ${SERVER_ENDPOINT} \
                  --concurrency ${CONCURRENCY} \
                  --batch-size-text ${BATCH_SIZE} \
                  --artifact-dir ${OUTPUT_DIR} \
                  --tokenizer ${MODEL_TOKENIZER} \
                  -- -v --max-threads=${CONCURRENCY} --request-count ${TOTAL_REQUESTS}
                  
                fi

              export PERCENT_COMPLETE=$((PERCENT_COMPLETE + 1))
              update_progress

              done
            done
            
            sleep 10

            export PERCENT_COMPLETE=100
            export EXPORT_FOLDER="nothing_new"
            update_progress
            echo "Finished Benchmarking! Sleeping for ${COMPLETION_DELAY:-60} seconds to allow the progress to be updated"
            sleep ${COMPLETION_DELAY:-60}

        env:
        - name: SERVER_HEALTH_CHECK_ENDPOINT
          value: {{ .Values.environment.SERVER_HEALTH_CHECK_ENDPOINT | quote }}
        - name: SERVER_ENDPOINT
          value: {{ .Values.environment.SERVER_ENDPOINT | quote }}
        - name: HF_TOKEN
          value: {{ .Values.environment.HF_TOKEN | quote }}
        - name: MODEL_NAME
          value: {{ .Values.environment.MODEL_NAME | quote }}
        - name: MODEL_NAME_CLEANED
          value: {{ .Values.environment.MODEL_NAME_CLEANED | quote }}
        - name: MIN_REQUESTS
          value: {{ .Values.environment.MIN_REQUESTS | quote }}
        - name: CONCURRENCY_RANGE
          value: {{ .Values.environment.CONCURRENCY_RANGE | quote }}
        - name: USE_CASES
          value: {{ .Values.environment.USE_CASES | quote }}
        - name: MODEL_TOKENIZER
          value: {{ .Values.environment.MODEL_TOKENIZER | quote }}
        - name: NUM_GPUS
          value: {{ .Values.environment.NUM_GPUS | quote }}
        - name: REQUEST_MULTIPLIER
          value: {{ .Values.environment.REQUEST_MULTIPLIER | quote }}
        - name: RESULTS_PATH
          value: {{ .Values.environment.RESULTS_PATH | quote }}
        - name: "NVCT_NCA_ID"
          value: {{ .Values.nvctNcaId | quote }}
        - name: "NVCT_TASK_ID"
          value: {{ .Values.nvctTaskId | quote }}
        - name: "NVCT_TASK_NAME"
          value: {{ .Values.nvctTaskName | quote }}
        - name: "NVCT_RESULTS_DIR"
          value: {{ .Values.nvctResultsDir | quote }}
        - name: "NVCT_PROGRESS_FILE_PATH"
          value: {{ .Values.nvctProgressFilePath | quote }}
  backoffLimit: 4