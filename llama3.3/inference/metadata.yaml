# Setup
general:
  workload: llama3.3
  workload_type: inference
  gsw_version: '25.08'
  framework: trt-llm

container:
  images:
    - 'nvcr.io#nvidia/tensorrt-llm/release:1.0.0rc4'

repositories:
  trt-llm:
    url: "https://github.com/NVIDIA/TensorRT-LLM.git"
    commit: "1a7c6e79743f100954e0a2375f254e54d5717e52"

setup:
  venv_req: true
  dependencies:
    git:
      trt-llm:
        repo_key: trt-llm
        install_method:
          type: clone
    pip:
      - 'huggingface_hub[cli]'
      - 'click==8.2.1'
      - 'transformers==4.52.4'
      - 'pillow==11.2.1'
      - 'datasets==3.6.0'
      - 'pydantic==2.11.7'
  tasks:
    - name: weights_download
      cmd: './download_weights.sh'
      job_type: local

# Run
run:
  launcher_type: 'sbatch'
  launch_script: 'launch.sh'

  gpu_configs:
    gb200:
      model_configs:
        - model_size: '70b'
          dtypes: ['nvfp4']
          scales: [1, 4]
          exact_scales: true
